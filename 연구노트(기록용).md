# 연구노트

**잘 동작하는 파서를 구현해보자.**

* **참고사이트**

  * [셀레니움4 공식문서](https://www.selenium.dev/documentation/webdriver/browsers/chrome/)
  * [셀레니움-오류해결 공유](https://cat-minzzi.tistory.com/28)
  * **[ERDCloud](https://www.erdcloud.com/d/N8nnR7nSiPHhx4BpL)**

* **bugfix는 발생마다 브랜치 새로 파서 해결 -> Issues 활용 -> merge pull 메인**

  * **git-Issues** -> #1,2,3... 으로 이슈와 커밋을 연결하는 방식 -> 해결하면 close까지 ㄱ

    ![image](https://github.com/user-attachments/assets/d37a7e51-e22b-4a5e-87eb-f8c8e010bed2)
    
     ![image](https://github.com/user-attachments/assets/0794a099-9ec2-4265-afb5-9e673e7680d8) 

* **깃으로 형상관리**

  * (1)보안을 위해 properties같은 파일에 따로 개인정보 기록 -> .env 사용!
  * (2)보안을 위해 .env 파일에 호스팅 서버에서만 동작하도록 리눅스 권한설정 (filezilla check)
  * (3)이후 public으로 깃 관리

* 기존 git-action 사용하던건?? -> 한동안 사용안할듯 함
  * 보통 코드 테스트용도로 많이쓰는걸로 아는데 이쪽으로 활용해보자.
  * 예로 그냥 로그인 필요없는 홈페이지 파싱같은건 쓸만하지 않겠나??
  * 정확히 어느정도 테스트에 쓰는지는 공부해보고 사용

* 호스팅 서버에 python동작을 cgi로 할거냐 장고로 할거냐?

  * 호스팅 서버에 동작시킬건데 셀레니움으로 파서만 구현할테니까 그냥 cgi 방식사용

* **성능개선은 ?? -> 아직안함:(1),(2)**

  * (1)**멀티스레드, 멀티프로세스** 적용해서 구현하는걸로 하자
  * (2)**Selenium Grid 4 (Docker Container)**: 하나의 script으로 원격 실행이 가능합니다. Docker의 Container를 사용해서 다수의 가상 머신에 Selenium을 배포하고 실행할 수 있습니다. 
    * 이거는 우선 넘어가고 나중에 도커를 잘 쓰게 될때 다시한번 체크해보자. 셀레니움4의 핵심추가기능

* 스케줄링(crontab) 으로 파서들 관리할 예정 -> 보통 하루 한번만 파싱하면 대부분 충분
  * 만약 자주 파싱해야할수도 있는 그런건 바로 파싱보다는 쿼리날려서 최신께 나왔는지 먼저 확인 필수

* DB에 데이터 저장을 할 것인가?? 아니면 xlsx?? -> DB

  * DB가 개인적으로 관리하기 편해서 DB로 전부 데이터 관리하겠음.
  * 전체 데이터 delete -> insert

* 셀레니움 최신꺼 사용, 파이썬 사용

  * 라이브러리도 최신껄로... 문법 무조건 다르니까 참고
  * 자바로할까 고민하긴했는데 보통 파이썬이 파싱하기엔 좋다고 하는듯

* `셀레니움` 에서는 BMP이상 범위의 문자들(예:이모티콘)을 인식하지 못한다.(지원하지 않음)  
  따라서 이들을 제거해서 사용해줘야 `send_keys` 가 가능하다. -> 필요할때 사용

  * 아래 코드를 함수로 작성해서 활용하는것을 추천
  * 0000-FFFF 까지가 BMP 범위이고, 10FFFF까지 SMP, SIP, TIP, SSP, PUA 공간이 잡혀있어서  
    10000-10FFFF까지 제거하는 것으로 정규식을 작성한 것이다.
    * [참고 문서](https://studyprogram.tistory.com/1)

  ```python
  import re # 정규식
  
  text = '안녕하세요 반갑습니다🐶' # 예시
  print(text) 
  only_BMP_pattern = re.compile("["
          u"\U00010000-\U0010FFFF"  #BMP characters 이외
                             "]+", flags=re.UNICODE)
  print(only_BMP_pattern.sub(r'', text))# BMP characters만
  ```

<br><br>

## 2024-09-30

**네이버 로그인 다시 정리 + 예외 로그 보기 힘들어서 main에 Exception처리 추가 ㄱ**

- 2단계 인증에 이메일or휴대폰인증 쪽 로직을 수행할 필요가 없음. (만들어 둔건 이메일 인증인데 놔두겠음.)
- **2단계 인증을 "네이버 앱"을 통해서 하고 있던 중.** (위 인증 이전에 먼저 체크하고 있음!)
  - **테스트 용으로 .env를 본인 네이버 id,pw로 바꿨기 때문에 다 끝나면 원복하기**

<br><br>

## 2023-10-20

**배포하면서 수정사항**

* (우선)div태그같은것들 클릭은 js로 수정, 속성같은 검색은 XPATH 사용으로 수정. **ok**
* cron사용시 작업환경을 python 실행파일 환경으로 변경 코드 추가. **ok**
* db중에 part db를 delete안해서 해당부분 코드 추가. **ok**

<br><br>

## 2023-10-12~

**이후 보완할점**

* 현재 파일이름을 별로 안좋게 활용중이라 따로 파일명 메모리에 기록해서 사용할수있도록 변경하자
* errorList 따로 db단에 기록(날짜별로) -> 현재는 log파일에만 출력중임
* (우선)smartstore프로젝트도 수정. **ok**
* (우선)parser 다른 웹들도 추가 파싱해보기
* log파일 백업파일 및 크기 제한 등. **ok**
  * RotatingFileHandler 적용! 백업 5개까지 및 크기제한 1MB
* (우선)product(네이버로그인)과 parse(네이버로그인X) 의 차이때문에 금일 product가 있는경우 바로 parse로 넘어가는 코드를 짜겠다. **ok**
  * 테스트(디버그)과정에서 parse에러시 이미 product는 성공했는데 매번 네이버로그인 및 파일다운이 굉장히 자원낭비 였기때문!
* (우선)div태그같은것들 클릭은 js로 수정, 속성같은 검색은 XPATH 사용으로 수정. **ok**

<br><br>

## 2023-10-09~11

**새로나온!! 엑셀일괄 수정!! 이것을 사용하자!!!!!**

* 즉, 이제 흐름은 ?? (참고로 인증은 "로그인때만 있음")
* **smartstore-parser(public)** : 네이버로그인 -> 로그인 한김에 상품정보.csv다운 -> page(name,url)전부 파싱 및 데이터파싱(b) 및 상품정보.csv 메모리에 읽어두기(a) ->  a와 b를 모델명(pk)끼리 비교해서 **a상품 순서대로(정렬)** 기록 및 **상품번호**는 필수 기록db(c). 전체delete후 insert
* **smartstore(private)** : 엑셀일괄수정.xlsx(d)다운 -> c(db)를 참고해서 d수정 -> d를 업로드 끝.
* 인증번호와 캡차내용은 둘다 메일로 받고, 사용자가 직접 메일을 내게쓰기 해서 해결
* url 다 숨기기. ok
* os.path.join(,) 위주로 경로 수정. ok
* 이상하게 파싱이 잘 안되는듯  ㅡ , ,, , ,, ? -> 직접 돌아가는거 하나하나 점검해야할듯. **parse 파일**
  * 디버깅 ㄱ -> 아... 단순 코드실수엿따 ㅜ ok
  * 옵션3 번째도 옵션1,2랑 이어서 기록해야함. 현재 따로 기록되어있어서 이부분 수정필요 ok
  * 또한 주의점으로 옵션명에 ' 가 들어가면 오류가 많아지므로 그런 상품은 그냥 무시 삭제 제거 ok

<br><br>

## 2023-10-06~08

**DB 설계는??**

* 아이템테이블 : 아이템_부속테이블 
  * 1:N 관계


**깃으로 형상관리 위해 env파일 .gitignore에 추가**

* .gitignore 을 git이 인식 못하는것 같을때 캐시삭제 후 다시 push

  ```bash
  git rm -r --cached .
  git add .
  git commit -m "fixed untracked files"
  ```

**프로젝트 생성.. -> 아나콘다로 환경설정..**

* `conda install pytz python-dotenv pandas openpyxl lxml selenium requests beautifulsoup4`
* 등등 라이브러리 여러개 한번에 설치 가능

**logging 라이브러리 활용 -> 로그레벨 사용**

* 근데 아마 debug레벨로 쓸듯 함. 다른사용자가 쓰는게 아니다보니.

**셀레니움 wait은 time.sleep, implicitly_wait은 사용X -> "Explicitly Wait 사용"**

* 최초 드라이버 생성 때 설정(**Implicitly_Wait** 기본값:0) : `driver.implicitly_wait(10)`
  * 10초전에 전체 DOM 로드시 더 안기다리고 바로 다음코드 진행
  * 10초 지나도 로드 안되면 예외
  * 추가로 timeout으로 설정된 시간 만큼 최대한 대기후 timeout Exception으로 넘어 갑니다.
* 매번 필요할때 사용(**Explicitly Wait**) : `WebDriverWait(browser, 5).until(EC.presence_of_element_located((By.XPATH, "//*[@id='maker_name']")))`
  * 5초전에 해당 엘리멘트 로드시 더 안기다리고 바로 다음코드 진행
  * 5초 지나도 로드안되면 예외
  * 추가로 timeout으로 설정된 시간 만큼 최대한 대기후 timeout Exception으로 넘어 갑니다.
* Explicitly Wait 가 코드는 복잡해져도,, 디버깅은 수월해지므로 오류검출 쉽게끔 이녀석만 사용하겠음
  * 딱히 timeout은 따로 안쓰겠다.
  * **시간초과 예외처리는 try catch로! 근데, 애초에 중간에 터지면 프로그램 다시 처리해야하다보니 try catch많이 안쓸듯** 

**셀레니움 엘리멘트 값 없을때 잘 넘어가기 위해 elements를 주로 써서 빈값은 []로 받자**

**정적으로 해결되면은 `request` 라이브러리 사용, 동적은 `셀레니움` 사용!!**

* **특히 로그인 필요사이트는 셀레니움 -> `request.Session` 사용!!**
  * **셀레니움으로 물론 다 가능하지만 request가 훨씬 속도는 빠르기 때문에 사용가능하면 꼭 쓰자.**
* **중요!!**
  * **자바스크립트 사용중지 체크해서 파싱 가능하다면 "정적"-request**
  * **그게 아니라면 "동적"-selenium**

**혹시나 div 클릭 등등 셀레니움에서 잘 동작하지 않는건 JS로 해결해보려고 할것**

* **또한, 속성같은것 검색할땐 XPATH 를 활용하면 더욱 간단**

  ```python
  option = dropdown3.find_element(by=By.XPATH,value='//*[@data-value="EDIT_FORM_DOWNLOAD"]')
  dropdown3.execute_script("arguments[0].click();", option)
  ```
